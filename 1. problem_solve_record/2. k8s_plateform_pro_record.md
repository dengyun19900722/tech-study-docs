###  0. 优秀博客

| 博文地址                                                     | 内容概述        | 备注 |
| ------------------------------------------------------------ | --------------- | ---- |
| https://tencentcloudcontainerteam.github.io/tke-handbook/damn/k8s-ipvs-bug.html | k8s故障解决参考 |      |
|                                                              |                 |      |
|                                                              |                 |      |



### 1. 网络

#### 1.1 Pod带宽限制插件踩坑之路？

v1.13.0 解决cannot set burst 的bug > v1.15.0解决带宽限制值/1000的问题（k8s各版本 bandwidth的bug）

#### 1.2 pod到kubernetes svc的网络不通？

##### 1.2.1 问题描述

​		某个pod到kubernetes（service）网络不通，报错：*UnkownHostException: kubernetes.default: Temporary failure in name resolution.*

##### 1.2.2 问题分析

>问题分析过程：
>
>1、检查pod所在节点的kube-proxy
>
>（1）ta所在节点的 kube-proxy实例未正常启动；
>
>（2）调度到别的节点后短暂可以，后面又挂了；
>
>2、定位再次挂掉的问题
>
>（3）此时问题变为了 > check/role/ 接口pending状态； 怀疑：节点到msp的网络有问题？？？
>
>3、定位节点到外部的网络问题
>
>（4）开始检查节点到msp的网络问题；
>
>4、检查确认网络没问题
>
>5、当前现象：服务出现间歇性的接口调用Pending没有返回；
>
>6、最后横向排查《选择两个终端访问》，新的终端正常 --> 得出结论：电脑可用内存不足导致浏览器访问异常；

##### 1.2.3 解决方案

​		适当关闭一些进程，空余足够的内存，访问恢复正常；

#### 1.3 apiserver突然挂掉？

##### 1.3.1 问题描述

​		获取集群节点信息时返回异常，报错：*The connection to. the server 12.2.2.2:6443 was refused - did you specify the right host or port？*

##### 1.3.2 问题分析

>**问题分析过程**
>
>1、检查是否apiserver已经挂掉？
>
>​      确认apiserver已经挂掉，原因磁盘空间占满，根据LRU算法，apiserver的镜像被删除，导致apiserver无法启动；
>
>2、启动secureregistryserver服务 > 启动本地镜像仓库。
>
> 	 启动完成后检查apiserver 容器，发现已正常启动，问题解决；
>
>3、现场情况特殊：kube-deploy不是第一个master节点，按上述操作后仍然无法拉取镜像。执行docker pull命令报错如下：
>
>```shell
>Error response from daemon：Get https://gci.io/v2/: dial tcp: lookup gci.io on 12.2.2.6:53: read udp 12.2.2.6:42013->12.2.2.6:53：i/o timeout
>```
>
>4、涉及问题：DNS管理问题 > bind9
>
>（1）确认kube-deploy节点的DNS服务器是使用的bind9？
>
>```shell
>netstat -anp | grep 53                  -- 53：dns服务器约定使用端口
>#拿到上面的命令获取的进程ID(eg：1051)
>ps -ef | grep 1051  > /usr/sbin/named -f -u bind (查询到这个结果代表DNS服务器是bind9)     
>```
>
>​		结论：确实是使用的bind9
>
>（2）确认DNS条目配置正常？
>
>```shell
>cd /etc/bind                             --bind9的工作目录
>cat named.conf.default-zones             --quary.io dns配置查看
>ping quary.io
>```
>
>5、apiserver的容器无法完成自启动？
>
>​	镜像已经可以成功拉取，但是apiserver还是无法自动重启成功，故而分析是否需要重启docker和kubelet；
>
>6、完成kubelet、docker重启。
>
>​	**apiserver正常启动，问题解决！！！**

##### 1.2.3 解决方案

​		清理磁盘  >> 重启secureregistryserver服务（==重启私有镜像仓库） >>  重启kubelet、docker

​		**！！！注意：es日志急需自动归档功能，可行方案：**

​            **（1）可程序自行实现定时每一个月删除一次索引；**

​            **（2）采用分布式存储集中管理磁盘资源、单独分区；**

#### 1.4 k8s kubelet PLEG is not healhy cause node NotReady?

http://blog.ittour.net/2019/09/25/container-runtime-is-down-pleg-is-not-healthy/

#### 1.5 IPVS is not working with hostport？

##### 1.5.1 问题描述

​		某个节点上的pod > 采用hostPort绑定主机端口模式对外暴露服务，但是hostPort访问不通；

![1570767220151](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\1570767220151.png)

##### 1.5.2 问题分析

> https://tencentcloudcontainerteam.github.io/tke-handbook/damn/k8s-ipvs-bug.html
>
> https://blog.csdn.net/zhangxiangui40542/article/details/79486995
>
> **1、iptables prerouting 网络地址转换规则，hostPort顺序 > kube-service，所以，当service与端口相同时流量会导到hostPort指定的pod**
>
> ​	原因：ipvs 和 iptables 都会向 netfilter 的 hook 点插入处理函数，由于 hostPort 是通过 iptables 实现的，所以当某节点的 pod 使用了 hostPort 暴露端口，就会写入 iptables 规则，让目标端口为该 hostPort 端口号的报文全部路由到该 pod；当启用 ipvs 来路由 service 时会写入 ipvs 规则，但写入的 ipvs 规则和 iptables 规则进入 netfilter 的 hook 点时，是有顺序的，netfilter 会先按顺序执行这些 hook 函数，iptables 规则的 hook 先被执行就会导致这个现象：该节点 pod 访问某个 service 的某个端口号，如果这个端口号跟 hostPort 一致，数据包就会被路由到 hostPort 对应的 pod 里
>
> ![1570719544572](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\1570719544572.png)
>
> **2、k8s pod 的hostPort端口模式原理：**
>
> ​		直接生成如下图所示的iptables规则（包含DNAT-目标地址转换-PREROUTING阶段和SNAT-源地址转换-POSTROUTING阶段），通过iptables接管hostPort的流量，并未生成主机LISTEN端口。
>
> ![、](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\1570759955414.png)



#### 1.6 DNS域名解析失败？

https://k8smeetup.github.io/docs/tasks/administer-cluster/dns-debugging-resolution/

#### 1.7 k8s集群部分node节点DNS解析突然失效？

##### 1.7.1 问题描述

​	某一个阳光明媚的早上，现场紧急保障：集群访问不了了？pod之间网络不通了？瞬时情转阴，抓紧时间一通排查。

##### 1.7.2 问题分析

​	因为集群pod的流量都是经过kube-proxy转发，所以第一步想到的是检查kube-proxy的状态？

> （1）排查方向1：检查故障节点的运行状态，发现运行正常？进行kube-proxy实例重启操作，仍未恢复。
>
> （2）排查方向2：查看kube-proxy日志，发现有报错，apiserver connect refused ？报错如下图所示；
>
> 进一步分析：k8s集群worker节点使用本机nginx反向代理的方式去连接apiserver，查看可知本节点的nginx-proxy pod不存在，然后去查本机nginx-proxy部署文件/etc/kubernetes/manifests/nginx-proxy.yml，发现文件不存在。
>
> （3）排查方向3：初步怀疑现场操作人员误删了部署文件；

![image-20200319090549918](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\image-20200319090549918.png)

##### 1.7.3 解决方案

​		从其他worker节点拷贝nginx-proxy.yml至故障节点，重启kubelet，问题解决。

#### 1.8 tcpdump未抓到需要的流量？

##### 1.8.1 问题描述

​	某一个风平浪静的下午，现场验收紧急报障，怎么我的服务访问流量抓不到包了，快速支援；

##### 1.8.2 问题分析



![image-20200318120849717](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\image-20200318120849717.png)

##### 1.8.3 解决方案

**1、抓包**

```shell
tcpdump -i 主机网卡名称 -w test-dump.pcap  # -i指定网卡，若不指定网卡则是默认抓取第一个网卡的流量包，*.pcap保存的是wireshark工具可解析的文件格式

tcpdump -i veth pair网卡名称 -w test-dump.pcap  # 抓pod的流量包
```

![image-20200317231956329](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\image-20200317231956329.png)

**2、分析：使用wireshark软件打开该文件即可**

![image-20200317230927594](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\image-20200317230927594.png)

#### 1.9 误操作占用apiserver的6443端口导致集群挂掉？

##### 1.9.1 问题描述

​		某一个下午，现场验收提出服务独立证书认证体系，于是乎开始对网关进行多端口暴露的改造测试，增加容器端口映射，主机多个端口映射到容器同一个端口，坏事了，1443-6443顺手配上了6443，完蛋，集群挂掉？

##### 1.9.2 问题分析

（1）容器每一个端口只能映射到外部端口，思路错误；

（2）误操作占用了apiserver端口，生产重大故障，是否可以增加端口冲突判断，nodePort是有端口冲突校验的？？？；

（3）**！！！！！！不要直接修改线上网关、若改错影响太广！！！！！**

##### 1.9.3 解决方案

> （1）修改apiserver部署文件的端口-6444，重启kubelet，完成apiserver的重装，
>
> （2）更新kubectl配置文件，保证kubectl可与集群通信；
>
> （3）更改traefik配置，删除traefik实例；
>
> （4）部分节点删除traefik 实例后还未恢复，重启服务器即可解决....

### 2. 集群组件

#### 2.1 k8s集群证书过期

1、证书更新

https://www.cnblogs.com/chineseall/p/10920361.html

https://stackoverflow.com/questions/54303469/kubelet-x509-certificate-is-valid-for-10-233-0-1-not-for-ip

```shell
kubeadm init phase certs apiserver --config=/etc/kubernetes/kubeadm-config.yaml
kubeadm init phase certs apiserver-kubelet-client --config=/etc/kubernetes/kubeadm-config.yaml
systemctl stop kubelet
delete the docker container with kubelet
systemctl restart kubelet
```

```shell
kubectl cluster-info
```

https://juejin.im/post/5cbe8b63f265da03826118e6 （证书查看）



https://www.cnblogs.com/aguncn/p/10488130.html (k8s证书体系)

sa.crt sa.pem - sa证书负责pod与apiserver的通信（by serviceaccount）

2、apiserver提供的服务

```shell 
Service（kubernetes.default） -> endpoint（kubernetes.default）

所有通过kubernetes域名去访问apiserver服务的请求都是通过该endpoint去转发；

请求apiserver的几种模式：
(1) curl https://ip:6443/version --insecure
(2) curl https://ip:6443 --ca-cert xxxxxxxx
(3) curl https://ip:6443 --token
```



 3、完整证书更新方案

https://blog.51cto.com/3138583/2400706\

4、其他master节点/etc/kubernets/被覆盖后问题修复？

（1）修改kubeadm-config.v1alpha3.yaml；

（2）执行命令：kubeadm alpha phase kubeconfig kubelet --config /etc/kubernetes/kubeadm-config.v1alpha3.yaml

#### 2.2 k8s集群证书过期解决方案

##### 2.2.1 主master节点恢复（部署节点）

###### 2.2.1.1 备份旧的证书、配置文件

```shell
#备份证书文件
sudo mv /etc/kubernetes/pki/apiserver.key /etc/kubernetes/pki/apiserver.key.old
sudo mv /etc/kubernetes/pki/apiserver.crt /etc/kubernetes/pki/apiserver.crt.old
sudo mv /etc/kubernetes/pki/apiserver-kubelet-client.crt /etc/kubernetes/pki/apiserver-kubelet-client.crt.old
sudo mv /etc/kubernetes/pki/apiserver-kubelet-client.key /etc/kubernetes/pki/apiserver-kubelet-client.key.old
sudo mv /etc/kubernetes/pki/front-proxy-client.crt /etc/kubernetes/pki/front-proxy-client.crt.old
sudo mv /etc/kubernetes/pki/front-proxy-client.key /etc/kubernetes/pki/front-proxy-client.key.old

#备份配置文件
sudo mv /etc/kubernetes/admin.conf /etc/kubernetes/admin.conf.old
sudo mv /etc/kubernetes/kubelet.conf /etc/kubernetes/kubelet.conf.old
sudo mv /etc/kubernetes/controller-manager.conf /etc/kubernetes/controller-manager.conf.old
sudo mv /etc/kubernetes/scheduler.conf /etc/kubernetes/scheduler.conf.old
```

###### 2.2.1.2 生成新的证书、配置文件

```shell
#生成新的证书 - kubeadm-config.xxxxx (kubeadm的配置文件-不同版本的k8s集群文件名不同，但前缀一致)
sudo kubeadm alpha phase certs apiserver --config /etc/kubernetes/kubeadm-config.v1alpha3.yaml
sudo kubeadm alpha phase certs apiserver-kubelet-client --config /etc/kubernetes/kubeadm-config.v1alpha3.yaml
sudo kubeadm alpha phase certs front-proxy-client --config /etc/kubernetes/kubeadm-config.v1alpha3.yam

#生成新的配置文件
sudo kubeadm alpha phase kubeconfig all --config /etc/kubernetes/kubeadm-config.v1alpha3.yaml --node-name k8s-master-1  # 加入 --node-name 参数是为了防止节点名与hostname不一致导致的kubelet生成的配置文件节点名称信息有误
### 如果报错：can not mix‘--config’ with arguments [node-name]则去掉后面的--node-name参数！！！
```

###### 2.2.1.3 更新kubectl认证文件

```shell
cp -rfp /etc/kubernetes/admin.conf ~/.kube/config
```

###### 2.2.1.4 重启相关服务

```shell
# 重启本机所有docker容器
docker restart $(docker ps -q)

# 重启kubelet
systemctl restart kubelet.service
```

###### 2.2.1.5 验证

```shell
kubectl get node
```

##### 2.2.2 其他master节点恢复

###### 2.2.2.1 拷贝部分配置文件、证书文件到其他master节点

```shell
# 注意千万不要拷贝kubelet.conf、kubeadm-config.v1alpha3.yaml文件到其它服务器（其它服务器自己生成）
#拷贝master组件相关配置文件到其他所有master节点
scp admin.conf controller-manager.conf scheduler.conf 10.18.60.4:/etc/kubernetes
#拷贝主master节点生成的证书文件到其他所有master节点
scp apiserver-kubelet-client.crt  apiserver-kubelet-client.key front-proxy-client.crt  front-proxy-client.key 10.18.60.4:/etc/kubernetes/pki

```

###### 2.2.2.2 生成kubelet配置文件

```shell
#备份配置文件
sudo mv /etc/kubernetes/kubelet.conf /etc/kubernetes/kubelet.conf.old
#生成kubelet配置文件
kubeadm alpha phase kubeconfig kubelet --config /etc/kubernetes/kubeadm-config.v1alpha3.yam --node-name k8s-master-x  # 加入 --node-name 参数是为了防止节点名与hostname不一致导致的kubelet生成的配置文件节点名称信息有误
```

###### 2.2.2.3 更新kubectl认证文件

```shell
cp -rfp /etc/kubernetes/admin.conf ~/.kube/config
```

###### 2.2.2.4 重启相关服务

```shell
# 重启本机所有docker容器
docker restart $(docker ps -q)

# 重启kubelet
systemctl restart kubelet.service
```

###### 2.2.2.5 验证

```shell
kubectl get node
```

##### 2.2.3 node节点恢复

###### 2.2.3.1 在主master节点重新生成token

```shell
kubeadm token create --ttl 0
```

###### 2.2.3.2 将node节点加入集群

```shell
#登录node服务器，执行下面的命令 - --ignore-preflight-errors 忽略检查错误
kubeadm join --token=cluster_token --di
scovery-token-unsafe-skip-ca-verification master_ip:6443 --ignore-preflight-errors all --node-name xxxx
```

#### 2.3 集群备份、迁移方案

##### 2.3.1 velero

```markdown
. 备份您的集群并在集群故障时进行恢复；
. 将本集群资源迁移到其他集群；
. 将生产集群复制到开发和测试集群。
```

##### 2.3.2 手动迁移

###### 1、k8s资源批量迁移脚本

```shell
#!/bin/bash
for n in $(kubectl get -o=name pvc,configmap,ingress,service,secret,deployment,statefulset,hpa,job,cronjob -n $1 | grep -v 'secret/default-token')
do
    kubectl -n $1 get -o=yaml --export $n > $(dirname $n)_$(basename $n).yaml
done

#$ bash migratiom.sh admin
外部服务正常迁移即可
数据服务：统一配置文件存放数据服务的参数配置，需要单独迁移
预警服务：ingress单独迁移
（1）admin命名空间采用排除法进行
grep -v -E 'datav-|cloud-front|dm-|......'
```



###### 2、镜像批量迁移脚本

```shell
#!/bin/bash
array=(alpine busybox)
imageVersion=latest
saveImagesStr=''
for(( i=0;i<${#array[@]};i++)) do
#${#array[@]}获取数组长度用于循环
  docker pull ${array[i]}:$imageVersion
  saveImagesStr="$saveImagesStr${array[i]}:$imageVersion "
done;
docker save -o $1 $saveImagesStr
```

```shell
#!/bin/bash
array=(imageName1,imageName2,...,imageNameN)
imageVersion=2.1.0
docker load -i $1
for(( i=0;i<${#array[@]};i++)) do
#${#array[@]}获取数组长度用于循环
	docker push ${array[i]}/$imageVersion
done;
```

###### 3、es迁移

```shell
#$ vim /etc/elasticsearch/elasticsearch.yml
reindex.remote.whitelist="otherhost:9200"  #otherhost - 源es集群的节点ip
systemctl restart elasticsearch
```



```shell
#!/bin/bash
if [ $# == 2 ]; then
    datebeg=$1
    dateend=$2
else
    echo "请输入开始时间和结束日期，格式为20170404"
    exit 1
fi

beg_s=`date -d "$datebeg" +%s`
end_s=`date -d "$dateend" +%s`

echo "处理时间范围：$beg_s 至 $end_s"

reindexEs(){
  curl -X POST "localhost:9200/_reindex?pretty" -H 'Content-Type: application/json' -d'
  {
        "source": {
                "remote": {
                        "host": "http://172.16.0.39:9200"
                },
                "index": "'"$1"'",
                "query": {
                        "match": {
                                "title": "elasticsearch"
                        }
                }
        },
        "dest": {
                "index": "'"$1"'"
        }
  }
  '
}

while [ "$beg_s" -le "$end_s" ];do
    day=`date -d @$beg_s +"%Y.%m.%d"`;
    index="traefik-access-$day"
    reindexEs $index
    beg_s=$((beg_s+86400));
done
```



```shell
#迁移过程 ssh登录25机器
cd /home/test/shujiang/es_migration/
bash xxxxx.sh  20191231 20200326  #迁移脚本 ：时间范围 - 2019-12-31 ~ 2020-03-26

#迁移后验证
curl http://esIp:9200/_cat/indices?pretty | grep traefik | sort
```



##### 2.3.2 脚本批处理（跨集群迁移）

#### 2.4 集群扩容、缩容

```shell
ansible-playbook -inventory/rong/hosts.ini scale.yml --extra-vars @rong-vars.yml

ansible-playbook -inventory/rong/hosts.ini remove-node.yml -b -v --extra-vars "node=node-5" @rong-vars.yml

velero create backup k8s-backup --exclude-namspaces velero
```

#### 2.5 configmap部署失败

##### 2.5.1 问题描述

​	执行下面的部署命令报错

```shell
kubectl apply -f cm.yml
```

```shell
The ConfigMap is invalid: metadata.annotations: Too long: must have at most 262144 characters
```



##### 2.5.2 问题分析

```shell
One of the downsides of using kubectl apply is that it stores the entire spec as an annotation in the object (which it uses to understand how handle defaulted vs. deleted fields).What's happening is that the data fields in the ConfiMap is likely exceeding 262144 characters enforced by the K8s API server, and thus it cannot fit in the last-applied-configuration kubectl annotation.

使用kubectl apply的缺点之一是，它将整个规范存储为对象中的注释（用于了解如何处理默认字段和已删除字段）.
这样会引发的情况是，ConfiMap中的数据字段可能超过了K8s API服务器强制执行的262144个字符，因此它不能容纳在最后应用的配置kubectl批注中。
```

##### 2.5.3 解决方案

​	使用create命令：

```
kubectl create -f cm.yml
```



### 3. 服务器 

#### 3.1 集群服务器时间错误？

#####  3.1.1 问题描述

​		使用飞鹏外网基于官方ubuntu180402做出的镜像重装后，后续发现时间快了8个小时？

#####  3.1.2 问题分析

​		原因：官网ubuntu镜像安装的linux是原生系统，Linux/Unix/Mac把计算机硬件时间当作 UTC， 所以在Linux/Unix/Mac系统启动后在该时间的基础上，加上电脑设置的时区数（ 比如我们在中国，它就加上“8” ），因此，Linux/Unix/Mac系统中显示的时间总是比Windows系统中显示的时间快8个小时。

#####  3.1.3 解决方案

https://blog.csdn.net/JesseYoung/article/details/43488351

1、方案一：ntpdate方式解決（ntpdate -- 与一个已知的时间服务器同步）

> （1）调整部署节点时间
>
> ```shell
> date -s "YYYY-MM-DD hh:mm[:ss]" 如date -s "2015-02-04 16:30:00"
> ```
>
> （2）部署节点执行同步命令
>
> ```shell
> ntpdate -u 210.72.145.44 :网络时间同步命令
> # 注意：若不加上-u参数， 会出现以下提示：no server suitable for synchronization found
> # -u：从 man ntpdate中可以看出-u参数可以越过防火墙与主机同步；
> ```
>
> （3）其他节点同步
>
> ```shell
> ntpdate -u 210.72.145.44 :网络时间同步命令
> # 注意：若不加上-u参数， 会出现以下提示：no server suitable for synchronization found
> # -u：从 man ntpdate中可以看出-u参数可以越过防火墙与主机同步；
> ```

2、方案二：

#### 3.2 集群节点上无法查看容器日志？

##### 3.2.1 问题描述

```shell
Failed to watch directory "/sys/fs/cgroup/memory/system.slice": inotify_add_watch /sys/fs/cgroup/memory/system.slice/run-docker-netns-c6d57b04b0f8.mount: no space left on device
```

##### 3.2.2 问题分析



##### 3.2.3 解决方案

```shell
# 查看pod所在节点
kubectl get po -n admin -owide | grep podName
# ssh 登录所在节点，执行下面的命令
sudo sysctl fs.inotify.max_user_watches=1048576 
sysctl -p
# 若不熟悉，可在所有节点执行该命令
```

