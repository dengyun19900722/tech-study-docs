### 0. 优秀博客

| 博文地址                                                     | 内容概述        | 备注 |
| ------------------------------------------------------------ | --------------- | ---- |
| https://tencentcloudcontainerteam.github.io/tke-handbook/damn/k8s-ipvs-bug.html | k8s故障解决参考 |      |
|                                                              |                 |      |
|                                                              |                 |      |



### 1. 网络

#### 1.1 Pod带宽限制插件踩坑之路？

v1.13.0 解决cannot set burst 的bug > v1.15.0解决带宽限制值/1000的问题（k8s各版本 bandwidth的bug）

#### 1.2 app 到kubernetes svc的网络不通？

##### 1.2.1 问题描述

​		某个pod到kubernetes（service）网络不通，报错：*UnkownHostException: kubernetes.default: Temporary failure in name resolution.*

##### 1.2.2 问题分析

>问题分析过程：
>
>1、检查pod所在节点的kube-proxy
>
>（1）ta所在节点的 kube-proxy实例未正常启动；
>
>（2）调度到别的节点后短暂可以，后面又挂了；
>
>2、定位再次挂掉的问题
>
>（3）此时问题变为了 > check/role/ 接口pending状态； 怀疑：节点到msp的网络有问题？？？
>
>3、定位节点到外部的网络问题
>
>（4）开始检查节点到msp的网络问题；
>
>4、检查确认网络没问题
>
>5、当前现象：服务出现间歇性的接口调用Pending没有返回；
>
>6、最后横向排查《选择两个终端访问》，新的终端正常 --> 得出结论：电脑可用内存不足导致浏览器访问异常；

##### 1.2.3 解决方案

​		适当关闭一些进程，空余足够的内存，访问恢复正常；

#### 1.3 apiserver突然挂掉？

##### 1.3.1 问题描述

​		获取集群节点信息时返回异常，报错：*The connection to. the server 12.2.2.2:6443 was refused - did you specify the right host or port？*

##### 1.3.2 问题分析

>**问题分析过程**
>
>1、检查是否apiserver已经挂掉？
>
>​      确认apiserver已经挂掉，原因磁盘空间占满，根据LRU算法，apiserver的镜像被删除，导致apiserver无法启动；
>
>2、启动secureregistryserver服务 > 启动本地镜像仓库。
>
> 	 启动完成后检查apiserver 容器，发现已正常启动，问题解决；
>
>3、现场情况特殊：kube-deploy不是第一个master节点，按上述操作后仍然无法拉取镜像。执行docker pull命令报错如下：
>
>```shell
>Error response from daemon：Get https://gci.io/v2/: dial tcp: lookup gci.io on 12.2.2.6:53: read udp 12.2.2.6:42013->12.2.2.6:53：i/o timeout
>```
>
>4、涉及问题：DNS管理问题 > bind9
>
>（1）确认kube-deploy节点的DNS服务器是使用的bind9？
>
>```shell
>netstat -anp | grep 53                  -- 53：dns服务器约定使用端口
>#拿到上面的命令获取的进程ID(eg：1051)
>ps -ef | grep 1051  > /usr/sbin/named -f -u bind (查询到这个结果代表DNS服务器是bind9)     
>```
>
>​		结论：确实是使用的bind9
>
>（2）确认DNS条目配置正常？
>
>```shell
>cd /etc/bind                             --bind9的工作目录
>cat named.conf.default-zones             --quary.io dns配置查看
>ping quary.io
>```
>
>5、apiserver的容器无法完成自启动？
>
>​	镜像已经可以成功拉取，但是apiserver还是无法自动重启成功，故而分析是否需要重启docker和kubelet；
>
>6、完成kubelet、docker重启。
>
>​	**apiserver正常启动，问题解决！！！**

##### 1.2.3 解决方案

​		清理磁盘  >> 重启secureregistryserver服务（==重启私有镜像仓库） >>  重启kubelet、docker

​		**！！！注意：es日志急需自动归档功能，可行方案：**

​            **（1）可程序自行实现定时每一个月删除一次索引；**

​            **（2）采用分布式存储集中管理磁盘资源、单独分区；**

#### 1.4 k8s kubelet PLEG is not healhy cause node NotReady?

http://blog.ittour.net/2019/09/25/container-runtime-is-down-pleg-is-not-healthy/

#### 1.5 IPVS is not working with hostport？

##### 1.5.1 问题描述

​		某个节点上的pod > 采用hostPort绑定主机端口模式对外暴露服务，但是hostPort访问不通；

![1570767220151](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\1570767220151.png)

##### 1.5.2 问题分析

> https://tencentcloudcontainerteam.github.io/tke-handbook/damn/k8s-ipvs-bug.html
>
> https://blog.csdn.net/zhangxiangui40542/article/details/79486995
>
> **1、iptables prerouting 网络地址转换规则，hostPort顺序 > kube-service，所以，当service与端口相同时流量会导到hostPort指定的pod**
>
> ​	原因：ipvs 和 iptables 都会向 netfilter 的 hook 点插入处理函数，由于 hostPort 是通过 iptables 实现的，所以当某节点的 pod 使用了 hostPort 暴露端口，就会写入 iptables 规则，让目标端口为该 hostPort 端口号的报文全部路由到该 pod；当启用 ipvs 来路由 service 时会写入 ipvs 规则，但写入的 ipvs 规则和 iptables 规则进入 netfilter 的 hook 点时，是有顺序的，netfilter 会先按顺序执行这些 hook 函数，iptables 规则的 hook 先被执行就会导致这个现象：该节点 pod 访问某个 service 的某个端口号，如果这个端口号跟 hostPort 一致，数据包就会被路由到 hostPort 对应的 pod 里
>
> ![1570719544572](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\1570719544572.png)
>
> **2、k8s pod 的hostPort端口模式原理：**
>
> ​		直接生成如下图所示的iptables规则（包含DNAT-目标地址转换-PREROUTING阶段和SNAT-源地址转换-POSTROUTING阶段），通过iptables接管hostPort的流量，并未生成主机LISTEN端口。
>
> ![、](C:\Users\dengy\AppData\Roaming\Typora\typora-user-images\1570759955414.png)



#### 1.6 DNS域名解析失败？

https://k8smeetup.github.io/docs/tasks/administer-cluster/dns-debugging-resolution/